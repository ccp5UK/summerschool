{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8de5a062",
   "metadata": {},
   "source": [
    "# Monte Carlo Integration (answers)\n",
    "## Introduction\n",
    "In this tutorial, you will explore the use of the Monte Carlo method to compute integrals. \n",
    "This will begin by illustrating the Metropolis method \n",
    "to sample from an arbitrary probability distribution.\n",
    "Then you will gain some experience \n",
    "in estimating the value of integrals with the Monte Carlo method, \n",
    "including the use of importance sampling. \n",
    "\n",
    "In the accompanying notebook, you will perform a Monte Carlo simulation in the\n",
    "$NVT$ ensemble for a shifted-truncated Lennard-Jones fluid.\n",
    "The two notebooks are independent of each other,\n",
    "but some basic ideas are introduced here,\n",
    "so we recommend that you start with this one.\n",
    "\n",
    "There is a third notebook in this directory,\n",
    "dealing with $NPT$ simulations of the Lennard-Jones fluid.\n",
    "This will be covered in a later workshop.\n",
    "\n",
    "## Preliminaries\n",
    "Start by importing some useful Python modules, \n",
    "setting up the random number generator,\n",
    "and loading a plotting style (feel free to change this as you wish)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efa48f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import dblquad\n",
    "from numpy.random import default_rng\n",
    "rng = default_rng()\n",
    "plt.style.use(['seaborn-v0_8-talk','seaborn-v0_8-darkgrid','seaborn-v0_8-colorblind'])\n",
    "plt.rc('image',cmap='viridis')\n",
    "plt.rc('legend',frameon=True,framealpha=1.0)\n",
    "plt.rc('hist',bins=100) # Default number of bins to use in histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ca2e82",
   "metadata": {},
   "source": [
    "## Metropolis sampling\n",
    "In this section, \n",
    "you will examine the use of the Metropolis method \n",
    "to sample points from an arbitrary probability distribution. \n",
    "The code in the following cells \n",
    "selects values for the variable $x$ from the probability distribution\n",
    "\\begin{equation*}\n",
    "P(x) = 12 \\, \\left( x - \\tfrac{1}{2} \\right)^{2}\n",
    "\\end{equation*}\n",
    "where $x \\in [0,1]$. \n",
    "This function is normalized on that range, \n",
    "although this is not necessary in order to do the sampling.\n",
    "In fact, we are going to omit the normalization factor from the function definition,\n",
    "simply to make this point.\n",
    "This is important when we come to do practical Metropolis Monte Carlo:\n",
    "in the canonical ensemble for many atoms, for instance, \n",
    "the normalization factor for the configurational distribution function is very hard to calculate\n",
    "(although, hopefully, you know what it is called?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df926e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def P(x):\n",
    "    \"\"\"Un-normalized probability function. Argument x may be scalar or NumPy array.\"\"\"\n",
    "    return (x-0.5)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d91634a",
   "metadata": {},
   "source": [
    "This implementation of the Metropolis method\n",
    "starts from an initial point $x_0 \\in [0,1]$,\n",
    "and generates trial points randomly and uniformly in that range.\n",
    "Suppose that $0,1,2,\\ldots, k$ trials have been carried out so far.\n",
    "The next trial point $x_t$ is accepted or rejected by comparing $P(x_t)$ with $P(x_k)$:\n",
    "\n",
    "* if $P(x_t) \\ge P(x_k)$, accept the trial;\n",
    "* if $P(x_t) < P(x_k)$, accept the trial with probability $P(x_t)/P(x_k)$, otherwise reject.\n",
    "\n",
    "Both the above tests can be combined in the following way,\n",
    "using a random number $0<u<1$ sampled from the standard uniform distribution:\n",
    "* If $\\dfrac{P(x_t)}{P(x_k)} \\ge u$ accept the trial, otherwise reject.\n",
    "\n",
    "Accepting the trial means $x_{k+1}=x_t$. \n",
    "Rejecting the trial means $x_{k+1}=x_k$.\n",
    "\n",
    "Hopefully, it is clear that, \n",
    "in a large set of values of $x$ sampled like this,\n",
    "those with high $P(x)$ will occur more often than those with low $P(x)$.\n",
    "It can be shown that the expected frequency of occurrence of $x$ is indeed\n",
    "proportional to $P(x)$.\n",
    "\n",
    "\n",
    "For convenience, a function `metropolis_1d` is defined to do this.\n",
    "The argument list consists of\n",
    "* the starting point, `x0`,\n",
    "* the range of sampling `xrange=(xmin,xmax)=(0.0,1.0)` in this case,\n",
    "* the sampling function `prob` which will be $P(x)$ when we call the function,\n",
    "* the number of points to be sampled, `n`.\n",
    "\n",
    "The function builds up a list of sampled points, and returns it as a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737b0406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_1d ( x0, xrange, prob, n ):\n",
    "    \"\"\"Carries out 1D sampling of specified probability function.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    x0 : float, scalar\n",
    "        starting point, must lie within xrange\n",
    "    xrange : tuple of scalar floats (xmin,xmax)\n",
    "        specified range\n",
    "    prob : function\n",
    "        specified probability function prob(x) of variable x\n",
    "    n : int, scalar\n",
    "        specified number of samples\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float, NumPy 1d array X of length n\n",
    "        contains the sampled x points\n",
    "    \"\"\"\n",
    "    \n",
    "    assert xrange[0] < x0 < xrange[1], 'x0 must be in xrange'\n",
    "    assert prob(x0) > 0,               'x0 must have prob(x0)>0'\n",
    "    xk = x0\n",
    "    X = []\n",
    "    for _ in range(n):\n",
    "        xt = rng.uniform(*xrange) # uniform random number in xrange\n",
    "        if prob(xt)/prob(xk) >= rng.uniform():\n",
    "            xk = xt\n",
    "        X.append(xk)\n",
    "    X = np.array(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ba9a84",
   "metadata": {},
   "source": [
    "This is how we use the function: call it with the desired arguments, including the probability function that we specified earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a22b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "n      = 10000\n",
    "xrange = (0.0,1.0)\n",
    "x0     = rng.uniform(*xrange) # random initial value in range\n",
    "X      = metropolis_1d(x0,xrange,P,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8e88c7",
   "metadata": {},
   "source": [
    "The next cell plots a probability histogram of the sampled values of $x$, \n",
    "along with the exact $P(x)$.\n",
    "The histogram is normalized numerically by selecting the `density=True` option.\n",
    "In plotting the exact $P(x)$, the correct normalizing factor is now included, \n",
    "since we want to compare visually with the simulated distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ab2b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.set_xlabel(r'$x$')\n",
    "ax.set_ylabel(r'$P(x)$')\n",
    "ax.set_xlim(xrange)\n",
    "ax.hist(X,range=xrange,density=True,label='sampled distribution')\n",
    "x = np.linspace(*xrange,501)\n",
    "Pnormed = 12*P(x)\n",
    "ax.plot(x,Pnormed,label='exact distribution')\n",
    "ax.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562dbbaa",
   "metadata": {},
   "source": [
    "From the sample, we can estimate averages and moments for this distribution,\n",
    "such as the mean value $\\langle x\\rangle$ and the variance $\\langle x^2\\rangle-\\langle x\\rangle^2$,\n",
    "calculated in the following cell.\n",
    "Again, we emphasize that this has been done without normalizing $P(x)$.\n",
    "Longer runs would give a more precise estimate.\n",
    "For comparison, the exact values are 0.5 and 0.15 respectively,\n",
    "which you can confirm algebraically by calculating integrals over $P(x)$,\n",
    "but this will involve knowing the normalizing factor!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3337c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Mean value of x = {X.mean():10.5f}')\n",
    "print(f'Variance of x   = {X.var():10.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8aa0d1",
   "metadata": {},
   "source": [
    "Now it's your turn. Your task is to sample, in a similar way, points from the distribution\n",
    "\\begin{equation*}\n",
    "P(x) = \\Bigl(\\frac{2}{L}\\Bigr) \\sin^{2} \\Big( \\frac{3 \\pi x}{L} \\Big)\n",
    "\\end{equation*}\n",
    "in the range $x \\in [0,L]$ where $L=5$.\n",
    "This function is defined in the next cell.\n",
    "Note that, in order to re-use the `metropolis_1d` routine,\n",
    "`P` is still a function of the single argument `x`,\n",
    "and the value of `L` is simply inherited from outside\n",
    "(not necessarily good practice in general!).\n",
    "Again, the normalization factor $(2/L)$ is omitted from the definition,\n",
    "but must be remembered when the exact function is plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8dfa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def P(x):\n",
    "    \"\"\"Un-normalized probability function. Argument x may be scalar or NumPy array.\"\"\"\n",
    "    return np.sin(3*np.pi*x/L)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122e7dc5",
   "metadata": {},
   "source": [
    "Over to you. \n",
    "Add statements to the next cell, defining `xrange` and `x0`,\n",
    "and using this function in a suitable call to `metropolis_1d`. \n",
    "Put the results, once more, in the array `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27e641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000\n",
    "L = 5.0\n",
    "# Inserted code\n",
    "xrange = (0.0,L)\n",
    "x0 = rng.uniform(*xrange)\n",
    "X = metropolis_1d(x0,xrange,P,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dd4418",
   "metadata": {},
   "source": [
    "The following cell compares the histogram of your `X` with the exactly known function.\n",
    "They should agree quite well, if the previous cell is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5fac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.set_xlabel(r'$x$')\n",
    "ax.set_ylabel(r'$P(x)$')\n",
    "ax.set_xlim(xrange)\n",
    "ax.hist(X,range=xrange,density=True,label='sampled distribution')\n",
    "x = np.linspace(*xrange,501)\n",
    "Pnormed = (2/L)*P(x)\n",
    "ax.plot(x,Pnormed,label='exact distribution')\n",
    "ax.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973f59bf",
   "metadata": {},
   "source": [
    "Now we aim to sample the two-dimensional distribution\n",
    "\\begin{equation*}\n",
    "P(x,y) = \\Bigl(\\frac{4}{L_x L_y}\\Bigr) \n",
    "\\sin^{2} \\Big( \\frac{2 \\pi x}{L_{x}} \\Big) \\, \n",
    "\\sin^{2} \\Big( \\frac{3 \\pi y}{L_{y}} \\Big)\n",
    "\\end{equation*}\n",
    "over the range $x\\in [0,L_x]$, $y\\in [0,L_y]$,\n",
    "where $L_{x}=3$ and $L_{y}=5$.\n",
    "Again, the values of `Lx` and `Ly` are inherited from outside by the function given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea5581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def P(x,y):\n",
    "    \"\"\"Un-normalized probability function. Arguments x, y may be scalars or NumPy arrays (of the same shape).\"\"\"\n",
    "    px = np.sin(2*np.pi*x/Lx)**2\n",
    "    py = np.sin(3*np.pi*y/Ly)**2\n",
    "    return px*py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ce5c8a",
   "metadata": {},
   "source": [
    "The approach is to write a new version of `metropolis_1d`,\n",
    "called `metropolis_2d`, for the 2D case.\n",
    "The skeleton of this function is given below,\n",
    "and it is up to you to insert the main loop.\n",
    "Two empty lists `X` and `Y` are defined,\n",
    "ready to contain the $x$ and $y$ coordinates of the sampled points.\n",
    "At each step, the current point is $(x_k,y_k)$.\n",
    "For the next sample, a new trial point $(x_t,y_t)$ should be chosen,\n",
    "randomly and uniformly within the specified area\n",
    "and a decision taken as to whether to accept it or reject it,\n",
    "based on the ratio $P(x_t,y_t)/P(x_k,y_k)$.\n",
    "Acceptance means that $(x_k,y_k)$ is replaced by $(x_t,y_t)$;\n",
    "rejection means that $(x_k,y_k)$ is left unchanged.\n",
    "Then these coordinates are appended to the lists,\n",
    "and the process moves on to the next step.\n",
    "The function converts the lists to arrays at the end, before returning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c3417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_2d ( x0, y0, xrange, yrange, prob, n ):\n",
    "    \"\"\"Carries out 2D sampling of specified probability function.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    x0, y0 : two floats, scalar\n",
    "        starting point, must lie within xrange, yrange\n",
    "    xrange : tuple of scalar floats (xmin,xmax)\n",
    "        specified range in x\n",
    "    yrange : tuple of scalar floats (ymin,ymax)\n",
    "        specified range in y\n",
    "    prob : function\n",
    "        specified probability function prob(x,y) of 2 variables x, y\n",
    "    n : int, scalar\n",
    "        specified number of samples\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    a tuple of two NumPy 1d arrays X, Y, of floats, length n\n",
    "        X contains the x coordinates of the sampled points\n",
    "        Y contains the y coordinates of the sampled points\n",
    "    \"\"\"\n",
    "    \n",
    "    assert xrange[0] < x0 < xrange[1], 'x0 must be in xrange'\n",
    "    assert yrange[0] < y0 < yrange[1], 'y0 must be in yrange'\n",
    "    assert prob(x0,y0) > 0,  '(x0,y0) must have prob(x0,y0)>0'\n",
    "    xk, yk = x0, y0\n",
    "    X, Y = [], []\n",
    "    # Inserted code\n",
    "    for _ in range(n):\n",
    "        xt, yt = rng.uniform(*xrange), rng.uniform(*yrange)\n",
    "        if prob(xt,yt)/prob(xk,yk) >= rng.uniform():\n",
    "            xk, yk = xt, yt\n",
    "        X.append(xk)\n",
    "        Y.append(yk)\n",
    "    X, Y = np.array(X), np.array(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746a610b",
   "metadata": {},
   "source": [
    "Once you have inserted the necessary statements,\n",
    "run the program in the following cell.\n",
    "Notice that the number of samples has been increased to $1000000$,\n",
    "because the dimensionality has gone up.\n",
    "This will take several seconds to run,\n",
    "so while you are testing you might like to temporarily reduce that number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c3fa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "n      = 1000000\n",
    "Lx, Ly = 3.0, 5.0\n",
    "xrange = (0.0,Lx)\n",
    "yrange = (0.0,Ly)\n",
    "x0, y0 = rng.uniform(*xrange), rng.uniform(*yrange)\n",
    "X, Y   = metropolis_2d(x0,y0,xrange,yrange,P,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d39bec1",
   "metadata": {},
   "source": [
    "Once you are happy, and have carried out the $1000000$-sample run,\n",
    "you can compare with with the theoretical result.\n",
    "For our purposes it is sufficient to produce side-by-side plots\n",
    "of the sample histogram (using `hist2d` from `matplotlib`),\n",
    "and contours for the theory (using `contourf` from `matplotlib`). \n",
    "Hopefully they look similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584e53de",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2,sharey=True,figsize=(7,5))\n",
    "ax1.set_xlabel(r'$x$')\n",
    "ax1.set_ylabel(r'$y$')\n",
    "ax2.set_xlabel(r'$x$')\n",
    "ax1.hist2d(X,Y,bins=100,range=[xrange,yrange],density=True)\n",
    "x   = np.linspace(*xrange,301)\n",
    "y   = np.linspace(*yrange,501)\n",
    "x,y = np.meshgrid(x,y)\n",
    "Pnorm = (2/Lx)*(2/Ly)*P(x,y)\n",
    "ax2.contourf(x,y,Pnorm)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b397a667",
   "metadata": {},
   "source": [
    "## Monte Carlo integration\n",
    "In this section, the Monte Carlo method is used to numerically integrate a simple function:\n",
    "\\begin{equation*}\n",
    "I = \\int_{0}^{L} dx \\, F(x) \\qquad\\text{where}\\quad F(x) = e^{-x} \\sin x\n",
    "\\end{equation*}\n",
    "and $L=100$.\n",
    "The exact result is\n",
    "\\begin{equation*}\n",
    "I = \\tfrac{1}{2} \\left[ 1 - e^{-L}(\\cos L + \\sin L) \\right] \\approx \\tfrac{1}{2}\n",
    "\\end{equation*}\n",
    "and for practical purposes, \n",
    "replacing $L=100$ by $L\\rightarrow\\infty$ would make no difference, \n",
    "as the integrand is vanishingly small for large $x$. \n",
    "However, as will become apparent, \n",
    "for most of this exercise a finite value of $L$ is needed. \n",
    "Note, in passing, that simple quadrature, \n",
    "rather than Monte Carlo, \n",
    "is almost always preferable for numerical estimation of \n",
    "low-dimensional integrals such as this; it is just for illustration.\n",
    "\n",
    "### Uniform sampling Monte Carlo\n",
    "The first approach is to estimate the integral \n",
    "using the straightforward Monte Carlo method, \n",
    "uniformly sampling $x \\in [0,L]$. \n",
    "Formally, the integral is being rewritten as\n",
    "\\begin{equation*}\n",
    "I = L \\times \\left[ \\frac{1}{L} \\int_{0}^{L} dx \\, F(x) \\right] \n",
    "= L \\times \\langle F(x) \\rangle\n",
    "= L \\times \\langle e^{-x} \\sin x \\rangle\n",
    "\\end{equation*}\n",
    "where $\\langle\\cdots\\rangle$ represents an average over the uniform distribution\n",
    "\\begin{equation*}\n",
    "P(x)= \\begin{cases} 1/L & 0 < x < L \\\\ 0 & \\text{otherwise} \\end{cases}\n",
    "\\end{equation*}\n",
    "This is implemented in the next cells.\n",
    "This code actually performs `s` MC simulations, \n",
    "each consisting of `n` sampled points. \n",
    "The `s` estimates of the integral from the simulations are stored in the array `Iuni`.\n",
    "The spread of results will give a guide to the (im)precision of\n",
    "a typical result from a single simulation.\n",
    "The direct sampling of $x$ values can be coded up very compactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa210104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F(x):\n",
    "    \"\"\"Function to be integrated\"\"\"\n",
    "    return np.exp(-x)*np.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217994a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 100.0\n",
    "xrange = (0.0,L)\n",
    "s = 1000\n",
    "n = 1000\n",
    "\n",
    "Iuni = []\n",
    "for _ in range(s):\n",
    "    X = rng.uniform(*xrange,size=n) # Uniformly sampled x values in xrange\n",
    "    I = L*np.average(F(X))          # Estimate of integral from above formula\n",
    "    Iuni.append(I)                  # Append this estimate to list\n",
    "Iuni = np.array(Iuni)\n",
    "\n",
    "# From these simulation estimates, calculate a mean value and standard deviation\n",
    "print(f'Uniform sampling: I = {Iuni.mean():8.5f}',u'\\u00B1',f'{Iuni.std():8.5f}')\n",
    "# Compare exact value\n",
    "I = 0.5*(1.0-np.exp(-L)*(np.sin(L)+np.cos(L)))\n",
    "print(f'Exact value:      I = {I:8.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcbc1c7",
   "metadata": {},
   "source": [
    "The distribution of estimates (and hence, the uncertainty in any one of them)\n",
    "can be visualized by creating a histogram of these values, and the following code does this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f677956",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.set_xlabel('Integral')\n",
    "ax.set_ylabel('Histogram')\n",
    "ax.set_xlim((0.0,1.0)) # Sensible likely range of estimates of integral\n",
    "ax.hist(Iuni,range=(0.0,1.0),label='uniform sampling') # Histogram of estimates of integral\n",
    "ax.axvline(x=I,c='k',label='exact value') # Exact value of integral\n",
    "ax.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b108c4e4",
   "metadata": {},
   "source": [
    "### Importance sampling\n",
    "In real life, we might do just one Monte Carlo estimate of such an integral,\n",
    "so the spread of results here is a little worrying,\n",
    "even if it is centred on the correct answer.\n",
    "This method can be improved by introducing importance sampling.\n",
    "Rather than uniformly sampling the entire possible range of $x$, \n",
    "attention is focused on regions where the value of the integrand,\n",
    "$e^{-x}\\sin x$,\n",
    "is significant.\n",
    "In this case, \n",
    "it might be worth sampling $x$ from \n",
    "the normalized probability distribution $P(x) = e^{-x}$. \n",
    "It is convenient (but not essential) \n",
    "to take $L\\rightarrow\\infty$. \n",
    "Formally, the integral is being rewritten as\n",
    "\\begin{equation*}\n",
    "I = \\int_{0}^{\\infty} dx \\, P(x) \\frac{F(x)}{P(x)}\n",
    "= \\left\\langle \\frac{F(x)}{P(x)} \\right\\rangle_P\n",
    "\\end{equation*}\n",
    "where $\\langle\\cdots\\rangle_P$ indicates an average over the distribution $P(x)$. \n",
    "The uniform sampling discussed in the previous section\n",
    "is just a special case of this formula,\n",
    "with $P(x)=1/L$ over the applicable range $[0,L]$ in that case.\n",
    "\n",
    "Note that, in this type of integration,\n",
    "we _do_ need to know the properly normalized $P(x)$\n",
    "in order to calculate the quantity being averaged, $F(x)/P(x)$!\n",
    "(In most Monte Carlo simulations, we are typically only calculating _ratios_ of\n",
    "integrals of this kind, so the normalizing factor once again is not needed).\n",
    "\n",
    "Finally, note that (in this case)\n",
    "the factor $e^{-x}$ within $F(x)$ happens to cancel exactly with $P(x)$,\n",
    "so we end up just calculating $\\langle\\sin x\\rangle_P$,\n",
    "but this is not essential for the method to work.\n",
    "\n",
    "For this simple case, \n",
    "the points can be sampled *directly*:\n",
    "a suitable random number generator is even built in to the NumPy library. \n",
    "This is implemented in the code below,\n",
    "which otherwise looks very similar to the previous cell,\n",
    "and stores the results in the array `Iexp`.\n",
    "The plot compares the spread of results with `Iuni`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f8fbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def P(x):\n",
    "    \"\"\"Probability function. Argument x may be scalar or NumPy array.\"\"\"\n",
    "    return np.exp(-x)\n",
    "def FoverP(x):\n",
    "    \"\"\"Function to be integrated divided by probability function\"\"\"\n",
    "    return F(x)/P(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b00033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s    = 1000\n",
    "n    = 1000\n",
    "Iexp = []\n",
    "for _ in range(s):\n",
    "    X = rng.standard_exponential(size=n) # Exponentially sampled x values\n",
    "    I = np.average(FoverP(X))            # Estimate of integral\n",
    "    Iexp.append(I)                       # Append to list\n",
    "Iexp = np.array(Iexp)\n",
    "\n",
    "# From these estimates, calculate a mean value and standard deviation\n",
    "print(f'Exponential sampling: I = {Iexp.mean():8.5f}',u'\\u00B1',f'{Iexp.std():8.5f}')\n",
    "# Compare exact value\n",
    "I = 0.5\n",
    "print(f'Exact value:          I = {I:8.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c130f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.set_xlabel('Integral')\n",
    "ax.set_ylabel('Histogram')\n",
    "ax.set_xlim((0.0,1.0)) # Sensible likely range of estimates of integral\n",
    "ax.hist(Iuni,range=(0.0,1.0),label='uniform sampling')\n",
    "ax.hist(Iexp,range=(0.0,1.0),alpha=0.8,label='exponential sampling')\n",
    "ax.axvline(x=I,color='k',label='exact value') # Exact value of integral\n",
    "ax.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665b43ac",
   "metadata": {},
   "source": [
    "### Markov chain random walk\n",
    "The exponential (importance) sampling should be *significantly* better,\n",
    "in the sense that the numerical results have a much narrower distribution\n",
    "around the exact value.\n",
    "In the more general case, however, \n",
    "it is not possible to sample the points directly. \n",
    "One alternative approach is to construct a Markov chain random walk. \n",
    "\n",
    "In this context, a chain is a sequence of coordinates $x_0,x_1,x_2,\\ldots, x_k, \\ldots$\n",
    "(we specialize to 1D for simplicity here).\n",
    "In a _Markov_ chain, the probability of generating the next value $x_{k+1}$\n",
    "depends solely on the current value $x_k$,\n",
    "not on the prior history of the chain.\n",
    "The `metropolis_1d` code presented earlier produces a Markov chain:\n",
    "the trial value $x_t$\n",
    "(chosen randomly and uniformly in the range $x_\\text{min}<x_t<x_\\text{max}$),\n",
    "is accepted ($x_{k+1}=x_t$) or rejected ($x_{k+1}=x_k$)\n",
    "by comparing $P(x_t)$ with $P(x_k)$.\n",
    "So we could use this for importance sampling based on\n",
    "the $P(x)=e^{-x}$ probability function,\n",
    "or any other probability distribution.\n",
    "\n",
    "In this section, we are going to refine this a little,\n",
    "and generate uniformly sampled trial values $x_t$ close to $x_k$, such that\n",
    "$x_k-\\Delta < x_t < x_k+\\Delta$,\n",
    "where $\\Delta$ is a relatively small number (the maximum step size).\n",
    "This step-by-step process is often called a _random walk_.\n",
    "An advantage of the method is that \n",
    "the probability of acceptance of such trial values can usually be made higher\n",
    "by reducing $\\Delta$,\n",
    "since then $x_t\\approx x_k$ and so $P(x_t)\\approx P(x_k)$.\n",
    "Provided some care is taken with the method of selecting the trial move,\n",
    "the same Metropolis criterion may be applied,\n",
    "to generate the desired distribution $P(x)$.\n",
    "A finite length system is used, \n",
    "bounded by $x_\\text{min}$ and $x_\\text{max}$ which are stored in `xrange`;\n",
    "trials are rejected if they fall outside this range,\n",
    "as well as if they fail the Metropolis criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc58a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk_1d ( x0, xrange, delta, prob, n ):\n",
    "    \"\"\"Carries out 1D sampling by random walk of specified function.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    x0 : float, scalar\n",
    "        starting point, must lie within xrange\n",
    "    xrange : tuple of scalar floats (xmin,xmax)\n",
    "        specified range\n",
    "    delta : float, scalar\n",
    "        maximum displacement\n",
    "    prob : function\n",
    "        specified probability function prob(x) of variable x\n",
    "    n : int, scalar\n",
    "        specified number of samples\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float, NumPy 1d array X of length n \n",
    "        contains the sampled x points\n",
    "    \"\"\"\n",
    "\n",
    "    assert xrange[0] < x0 < xrange[1], 'x0 must be in xrange'\n",
    "    assert prob(x0) > 0,               'x0 must have prob(x0)>0'\n",
    "    xk = x0\n",
    "    X = []\n",
    "    for _ in range(n):\n",
    "        xt = xk + rng.uniform(-delta,delta) # Random walk step\n",
    "        if xrange[0] < xt < xrange[1]:\n",
    "            if prob(xt)/prob(xk) >= rng.uniform():\n",
    "                xk = xt\n",
    "        X.append(xk)\n",
    "    X = np.array(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc20d92f",
   "metadata": {},
   "source": [
    "The random walk is implemented in the cells below,\n",
    "again attempting to sample from the $P(x)=\\exp(-x)$ distribution,\n",
    "to integrate $F(x)=\\exp(-x)\\sin x$.\n",
    "We re-use the functions `P(x)` and `FoverP(x)` defined above.\n",
    "\n",
    "Each simulation consists, once more, of `n=1000` sampled points,\n",
    "within the range $x\\in[0,L]$ where $L = 100$.\n",
    "The starting point `x0` is chosen at the midpoint of the range $[0,L]$.\n",
    "Do you think that this is a good idea?\n",
    "Maybe we should re-examinine this afterwards.\n",
    "Once more the program performs `s=1000` MC simulations, \n",
    "so the distribution of answers gives an idea of precision.\n",
    "In the plot, comparison is made with the other two methods: \n",
    "uniform sampling and importance sampling directly from the exponential distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb5fcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s       = 1000\n",
    "n       = 1000\n",
    "delta   = 2.5\n",
    "L       = 100.0\n",
    "xrange  = (0.0,L)\n",
    "x0      = 0.5*L\n",
    "\n",
    "Iwlk = []\n",
    "for _ in range(s):\n",
    "    X = random_walk_1d(x0,xrange,delta,P,n) # Exponentially sampled x values\n",
    "    I = np.average(FoverP(X))               # Estimate of integral\n",
    "    Iwlk.append(I)                          # Append to list\n",
    "Iwlk = np.array(Iwlk)\n",
    "\n",
    "# From these estimates, calculate a mean value and standard deviation\n",
    "print(f'Random walk: I = {Iwlk.mean():8.5f}',u'\\u00B1',f'{Iwlk.std():8.5f}')\n",
    "# Compare exact value\n",
    "I = 0.5*(1.0-np.exp(-L)*(np.sin(L)+np.cos(L)))\n",
    "print(f'Exact value: I = {I:8.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c416f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.set_xlabel('Integral')\n",
    "ax.set_ylabel('Histogram')\n",
    "ax.set_xlim((0.0,1.0))\n",
    "ax.hist(Iuni,range=(0.0,1.0),label='uniform sampling')\n",
    "ax.hist(Iexp,range=(0.0,1.0),label='exponential sampling')\n",
    "ax.hist(Iwlk,range=(0.0,1.0),alpha=0.8,label='random walk')\n",
    "ax.axvline(x=I,color='k',label='exact value')\n",
    "ax.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab6081e",
   "metadata": {},
   "source": [
    "There should be some good points, and some bad points, in the above plot. \n",
    "Spend some time thinking about the questions below,\n",
    "particularly the first two,\n",
    "perhaps experimenting with the code in the cells above.\n",
    "\n",
    "1. How does the precision of the random walk method compare with that of the uniform MC method, and the direct exponential sampling method? (Precision relates to the spread in results). How about the accuracy? (This relates to  how close the results are to the correct answer).\n",
    "2. Concerning the systematic inaccuracy, could the starting position for the random walk be chosen in a better way? Make a more sensible choice, and re-run the random walk.\n",
    "3. How do the precision and accuracy of the estimate of the integral vary with the number of points sampled in the simulation?\n",
    "4. How does the precision of the random walk method vary with the `delta` parameter? (We expect this to be connected with the fraction of trials accepted, which is not calculated above).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50513996",
   "metadata": {},
   "source": [
    "## Comments\n",
    "\n",
    "Here are a few observations about the examples of 1D integration by Monte Carlo.\n",
    "\n",
    "Importance sampling should give a smaller variance than uniform sampling, \n",
    "which suffers from the fact that the sampled range $[0,L]$ is quite large,\n",
    "with $L=100$,\n",
    "compared with the range over which the integrand is significant. \n",
    "Directly sampling from the exponential distribution automatically concentrates\n",
    "the effort in the region where the integrand is largest.\n",
    "\n",
    "The Markov chain random walk method has a couple of parameters which may affect both\n",
    "the systematic and statistical error:\n",
    "the step size, and the starting point.\n",
    "In a similar way to atomistic simulation,\n",
    "using a smaller step size may increase the acceptance ratio of moves\n",
    "(which we don't monitor directly in the notebook)\n",
    "while at the same time slowing down the walk.\n",
    "So we expect a trade-off somewhere,\n",
    "and the best step size might well be comparable with the range of the exponential function\n",
    "(which is unity here).\n",
    "\n",
    "Using the random walk method is also susceptible to a systematic error, \n",
    "because we suggested choosing the starting point at the midpoint of the sampled range,\n",
    "$L/2=50$.\n",
    "This is well outside the important region of the integrand.\n",
    "It takes a while to reach the important region by random walk, \n",
    "and during this equilibration period (which is not discarded), \n",
    "the sampled values will bias the final average towards low values. \n",
    "Choosing the starting point randomly within the sampled range $[0,L]$\n",
    "will (most likely) not be any better. \n",
    "If the initial value is chosen quite close to $x=0$, \n",
    "this problem becomes less critical. \n",
    "Also, if the length of the Markov chain is significantly increased, \n",
    "the effect of the equilibration period on the final result will be reduced.\n",
    "Of course, in atomistic simulations,\n",
    "we are used to the idea of discarding an initial, equilibration, run,\n",
    "but we are always faced with the question: did we equilibrate for long enough?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cba01f6",
   "metadata": {},
   "source": [
    "### Two-dimensional importance sampling\n",
    "If time permits, use one of the above approaches to numerically estimate the value of the integral\n",
    "\\begin{equation*}\n",
    "I = \\int_{-\\infty}^{\\infty} dx \\int_{-\\infty}^{\\infty} dy \\, \n",
    "F(x,y)\n",
    "\\quad \\text{where} \\quad\n",
    "F(x,y) = \\exp \\bigl[ -(x^{2}+y^{2})^{2}+x^{2} \\bigr] .\n",
    "\\end{equation*}\n",
    "The value is $I\\approx 3.94476$, obtained by standard quadrature,\n",
    "as we can see in the following cell which uses `dblquad`,\n",
    "imported from the `scipy.integrate` sub-package at the top of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef273c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F(x,y):\n",
    "    \"\"\"Function to be integrated.\"\"\"\n",
    "    return np.exp(-(x**2+y**2)**2+x**2)\n",
    "\n",
    "I, Ierr = dblquad ( F, -np.inf, np.inf, -np.inf, np.inf )\n",
    "print(f'Quadrature value = {I:8.5f}')\n",
    "print(f'Estimated error  = {Ierr:8.1e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c318a8a9",
   "metadata": {},
   "source": [
    "Do this by importance sampling, using the double-Gaussian probability density\n",
    "\\begin{equation*}\n",
    "P(x,y) = p(x) p(y) \\quad\\text{where}\\quad p(x) = \\frac{1}{\\sqrt{\\pi}} e^{-x^{2}}\n",
    "\\end{equation*}\n",
    "This means that we are evaluating the integral as follows\n",
    "\\begin{equation*}\n",
    "I = \\int_{-\\infty}^{\\infty} dx \\int_{-\\infty}^{\\infty} dy \\, \n",
    "P(x,y) \\, \\frac{F(x,y)}{P(x,y)}\n",
    "= \\left\\langle \\frac{F(x,y)}{P(x,y)}\\right\\rangle_P\n",
    "\\end{equation*}\n",
    "where $\\langle\\cdots\\rangle_P$ denotes an average over $P$.\n",
    "Three approaches spring to mind. \n",
    "If time is short, feel free to postpone thinking about these until after the workshop!\n",
    "\n",
    "1. Recognize $p(x)$ as the normal distribution with mean $\\mu=0$ and variance $\\sigma^2=\\frac{1}{2}$, i.e. standard deviation $\\sigma=\\sqrt{\\frac{1}{2}}$. There is a random number function for this in the NumPy library, `rng.normal`.\n",
    "You can use it to sample $P(x,y)$ directly.\n",
    "2. Do Metropolis sampling, in a square box $-L < x,y < L$, accepting or rejecting moves according to $P(x,y)$. The function `metropolis_2d` above, can do this, without any changes. You'll need to choose $L$ large enough that the integrand is essentially zero at the boundary: $L=2.5$ should be OK.\n",
    "3. Do a Markov chain random walk in 2D, adapting the earlier `random_walk_1d` function into a 2D version `random_walk_2d`, and otherwise following the general scheme of the Metropolis sampler.\n",
    "\n",
    "For convenience the necessary additional functions are defined in the following cell.\n",
    "To get an idea of the reliability of the answer, again conduct `s=1000` independent simulations,\n",
    "and plot the distribution of results.\n",
    "However, for a 2D example, the number of samples should be increased: `n=5000` may be a good starting point.\n",
    "Note: running the Metropolis or random walk sampler may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d88d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def P(x,y):\n",
    "    \"\"\"Normalized probability density.\"\"\"\n",
    "    return np.exp(-x**2-y**2)/np.pi\n",
    "def FoverP(x,y):\n",
    "    \"\"\"Integrand F divided by probability density P.\"\"\"\n",
    "    return F(x,y) / P(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45b4678",
   "metadata": {},
   "source": [
    "In the following 2 cells, the normal distributions are sampled directly, and the distribution of results is plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebd6c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "s    = 1000\n",
    "n    = 5000\n",
    "Inor = []\n",
    "for _ in range(s):\n",
    "    X = rng.normal(0.0,np.sqrt(0.5),size=n ) # Normally sampled x values\n",
    "    Y = rng.normal(0.0,np.sqrt(0.5),size=n ) # Normally sampled y values\n",
    "    I = np.average(FoverP(X,Y))              # Estimate of integral\n",
    "    Inor.append(I)                           # Append to list\n",
    "Inor  = np.array(Inor)\n",
    "print(f'Normal sampling:  I = {Inor.mean():8.5f}',u'\\u00B1',f'{Inor.std():8.5f}')\n",
    "# Compare quadrature value\n",
    "I, Ierr = dblquad ( F, -np.inf, np.inf, -np.inf, np.inf )\n",
    "print(f'Quadrature value: I = {I:8.5f}',u'\\u00B1',f'{Ierr:8.1e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bc7636",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.set_xlabel('Integral')\n",
    "ax.set_ylabel('Histogram')\n",
    "ax.set_xlim((3.5,4.5)) # Sensible likely range of estimates of integral\n",
    "ax.hist(Inor,range=(3.5,4.5),label='normal sampling')\n",
    "ax.axvline(x=I,color='k',label='quadrature')\n",
    "ax.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7836ee83",
   "metadata": {},
   "source": [
    "In the following 2 cells, the double-normal distribution is sampled \n",
    "using the Metropolis method over a finite range $-L\\ldots L$ in both $x$ and $y$.\n",
    "This takes a few minutes.\n",
    "The distribution of results is plotted.\n",
    "We compare with the direct normal sampling result just obtained (for infinite range),\n",
    "and with the quadrature value for the finite range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af25e647",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 1000\n",
    "n = 5000\n",
    "L = 2.5\n",
    "xrange = (-L,L)\n",
    "yrange = (-L,L)\n",
    "x0, y0 = 0.0,0.0\n",
    "Imet  = []\n",
    "for _ in range(s):\n",
    "    X, Y = metropolis_2d(x0,y0,xrange,yrange,P,n)\n",
    "    I    = np.average(FoverP(X,Y))\n",
    "    Imet.append(I)\n",
    "Imet  = np.array(Imet)\n",
    "print(f'Metropolis sampling: I = {Imet.mean():8.5f}',u'\\u00B1',f'{Imet.std():8.5f}')\n",
    "I, Ierr = dblquad ( F, -L, L, -L, L )\n",
    "print(f'Quadrature value:    I = {I:8.5f}',u'\\u00B1',f'{Ierr:8.1e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0551230",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.set_xlabel('Integral')\n",
    "ax.set_ylabel('Histogram')\n",
    "ax.set_xlim((3.5,4.5)) # Sensible likely range of estimates of integral\n",
    "ax.hist(Inor,range=(3.5,4.5),label='normal sampling')\n",
    "ax.hist(Imet,range=(3.5,4.5),alpha=0.8,label='Metropolis sampling')\n",
    "ax.axvline(x=I,color='k',label='quadrature')\n",
    "ax.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582915d5",
   "metadata": {},
   "source": [
    "Finally, in the following 3 cells, \n",
    "a 2D Markov chain random walk is defined and carried out (again taking a few minutes),\n",
    "and the distribution of results plotted.\n",
    "Once more, we compare with the direct normal sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296e6332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk_2d ( x0, y0, xrange, yrange, delta, prob, n ):\n",
    "    \"\"\"Carries out 2D sampling by random walk of specified probability function.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    x0, y0 : two floats, scalar\n",
    "        starting point, must lie within xrange, yrange\n",
    "    xrange : tuple of scalar floats (xmin,xmax)\n",
    "        specified range in x\n",
    "    yrange : tuple of scalar floats (ymin,ymax)\n",
    "        specified range in y\n",
    "    delta : float, scalar\n",
    "        maximum displacement\n",
    "    prob : function\n",
    "        specified probability function prob(x,y) of 2 variables x, y\n",
    "    n : int, scalar\n",
    "        specified number of samples\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    a tuple of two NumPy 1d arrays X, Y, of floats, length n\n",
    "        X contains the x coordinates of the sampled points\n",
    "        Y contains the y coordinates of the sampled points\n",
    "    \"\"\"\n",
    "\n",
    "    assert xrange[0] < x0 < xrange[1], 'x0 must be in xrange'\n",
    "    assert yrange[0] < y0 < yrange[1], 'y0 must be in yrange'\n",
    "    assert prob(x0,y0) > 0,  '(x0,y0) must have prob(x0,y0)>0'\n",
    "\n",
    "    xk, yk = x0, y0\n",
    "    X, Y = [], []\n",
    "    for _ in range(n):\n",
    "        xt = xk + rng.uniform(-delta,delta)\n",
    "        yt = yk + rng.uniform(-delta,delta)\n",
    "        if xrange[0] < xt < xrange[1] and yrange[0] < yt < yrange[1]:\n",
    "            if prob(xt,yt)/prob(xk,yk) >= rng.uniform():\n",
    "                xk, yk = xt, yt\n",
    "        X.append(xk)\n",
    "        Y.append(yk)\n",
    "    X, Y = np.array(X), np.array(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bd25b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 1000\n",
    "n = 5000\n",
    "L = 2.5\n",
    "delta = 0.5\n",
    "xrange = (-L,L)\n",
    "yrange = (-L,L)\n",
    "x0, y0 = 0.0, 0.0\n",
    "Iwlk  = []\n",
    "for _ in range(s):\n",
    "    X, Y = random_walk_2d(x0,y0,xrange,yrange,delta,P,n)\n",
    "    I = np.average(FoverP(X,Y))\n",
    "    Iwlk.append(I)\n",
    "Iwlk  = np.array(Iwlk)\n",
    "print(f'Random walk sampling: I = {Iwlk.mean():8.5f}',u'\\u00B1',f'{Iwlk.std():8.5f}')\n",
    "I, Ierr = dblquad ( F, -L, L, -L, L )\n",
    "print(f'Quadrature value:     I = {I:8.5f}',u'\\u00B1',f'{Ierr:8.1e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cc0b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.set_xlabel('Integral')\n",
    "ax.set_ylabel('Histogram')\n",
    "ax.set_xlim((3.5,4.5)) # Sensible likely range of estimates of integral\n",
    "ax.hist(Inor,range=(3.5,4.5),label='normal sampling')\n",
    "ax.hist(Iwlk,range=(3.5,4.5),alpha=0.8,label='random walk')\n",
    "ax.axvline(x=I,color='k',label='quadrature')\n",
    "ax.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235ab954",
   "metadata": {},
   "source": [
    "This concludes the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2b19f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
